import whisper
import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import tempfile
import os

# Load the Whisper model (medium recommended for Hindi-English)
model = whisper.load_model("medium")

import sounddevice as sd
import scipy.io.wavfile as wav

def record_audio(filename, duration=5, fs=44100):
    print("üé§ ‡§¨‡•ã‡§≤‡§ø‡§è... (Speak now)")
    try:
        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()
        print("‚úÖ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§™‡•Ç‡§∞‡•Ä ‡§π‡•ã ‡§ó‡§à‡•§")
        wav.write(filename, fs, recording)
    except Exception as e:
        print(f"[‚ùå] ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")


def transcribe_audio():
    audio_path = record_audio()
    if not audio_path:
        return ""

    try:
        result = model.transcribe(audio_path, language="hi")  # You can use 'auto' for auto-detection
        os.remove(audio_path)  # Clean up temp file
        return result.get("text", "").strip()
    except Exception as e:
        print(f"[‚ùå] ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {e}")
        return ""
